#coding:utf-8
import cv2
import streamlit as st
import mediapipe as mp
from process_frame_2 import ExerciseCounter
from thresholds import get_thresholds_beginner, get_thresholds_pro

mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose

# UI ç•Œé¢
st.title("AI åŠ¨ä½œè¯†åˆ«å¥èº«æ•™ç»ƒ ğŸ’ª")
exercise = st.selectbox("é€‰æ‹©åŠ¨ä½œ", ["æ·±è¹²", "ä¿¯å§æ’‘", "ä»°å§èµ·å"])
mode = st.radio("é€‰æ‹©æ¨¡å¼", ["åˆå­¦è€…", "ä¸“ä¸š"])

# ä¸­æ–‡ -> è‹±æ–‡æ˜ å°„
exercise_map = {"æ·±è¹²": "squat", "ä¿¯å§æ’‘": "pushup", "ä»°å§èµ·å": "situp"}
exercise_eng = exercise_map[exercise]

# åŠ è½½é˜ˆå€¼
thresholds = get_thresholds_beginner(exercise_eng) if mode == "åˆå­¦è€…" else get_thresholds_pro(exercise_eng)

st.write(f"å½“å‰é€‰æ‹©: {exercise} - {mode}")
stframe = st.empty()

# æ‰“å¼€æ‘„åƒå¤´
cap = cv2.VideoCapture(0)

counter = ExerciseCounter(exercise_eng, thresholds)

with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # Mediapipe å¤„ç†
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False
        results = pose.process(image)
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            image, count = counter.process(landmarks, image)
            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        stframe.image(image, channels="BGR")

cap.release()

#coding:utf-8
import streamlit as st
import cv2
import tempfile
import os
import mediapipe as mp
from process_frame_2 import ExerciseCounter
from thresholds import get_thresholds_beginner, get_thresholds_pro

mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose

st.title("AI å¥èº«æ•™ç»ƒï¼šå®æ—¶+è§†é¢‘åŠ¨ä½œåˆ†æ ğŸ’ªğŸ¬")

mode_select = st.radio("é€‰æ‹©æ¨¡å¼", ["æ‘„åƒå¤´å®æ—¶è¯†åˆ«", "ä¸Šä¼ è§†é¢‘è¯†åˆ«"])
exercise = st.selectbox("é€‰æ‹©åŠ¨ä½œ", ["æ·±è¹²", "ä¿¯å§æ’‘", "ä»°å§èµ·å", "å¼•ä½“å‘ä¸Š", "è·³ç»³"])
level = st.radio("é€‰æ‹©éš¾åº¦", ["åˆå­¦è€…", "ä¸“ä¸š"])

exercise_map = {"æ·±è¹²": "squat", "ä¿¯å§æ’‘": "pushup", "ä»°å§èµ·å": "situp", "å¼•ä½“å‘ä¸Š": "pullup", "è·³ç»³":"jump_rope"}
exercise_eng = exercise_map[exercise]

thresholds = get_thresholds_beginner(exercise_eng) if level=="åˆå­¦è€…" else get_thresholds_pro(exercise_eng)
counter = ExerciseCounter(exercise_eng, thresholds)
st.write(f"å½“å‰é€‰æ‹©: {exercise} - {level}")

# ---------------- å®æ—¶æ‘„åƒå¤´ ----------------
if mode_select == "æ‘„åƒå¤´å®æ—¶è¯†åˆ«":
    stframe = st.empty()
    cap = cv2.VideoCapture(0)
    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = pose.process(image)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                image, _ = counter.process(landmarks, image)
                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            stframe.image(image, channels="BGR")
    cap.release()

# ---------------- ä¸Šä¼ è§†é¢‘ ----------------
elif mode_select == "ä¸Šä¼ è§†é¢‘è¯†åˆ«":
    uploaded_file = st.file_uploader("ä¸Šä¼ è§†é¢‘æ–‡ä»¶", type=["mp4","avi","mov"])
    if uploaded_file is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_file.read())
        video_path = tfile.name

        cap = cv2.VideoCapture(video_path)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        out_path = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4").name
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

        stframe = st.empty()
        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                image.flags.writeable = False
                results = pose.process(image)
                image.flags.writeable = True
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
                if results.pose_landmarks:
                    landmarks = results.pose_landmarks.landmark
                    image, _ = counter.process(landmarks, image)
                    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                out.write(image)
                stframe.image(image, channels="BGR")
        cap.release()
        out.release()

        with open(out_path, "rb") as f:
            st.download_button(
                label="ä¸‹è½½åˆ†æåè§†é¢‘",
                data=f,
                file_name=f"analyzed_{uploaded_file.name}",
                mime="video/mp4"
            )
        os.remove(video_path)
        os.remove(out_path)
